{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from rosbags.highlevel import AnyReader\n",
    "from sensor_msgs.msg import PointCloud2,  PointField\n",
    "import struct\n",
    "import numpy as np\n",
    "import math \n",
    "import open3d as o3d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Editing ROS2 bag\n",
    "saving only the topics you need to ROS2 data.db3\n",
    "### works only with standard ros messages \n",
    "find the list of supported messages [here](https://ternaris.gitlab.io/rosbags/topics/typesys.html#included-message-types): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import TYPE_CHECKING, cast\n",
    "\n",
    "from rosbags.interfaces import ConnectionExtRosbag2\n",
    "from rosbags.rosbag2 import Reader, Writer\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from pathlib import Path\n",
    "\n",
    "\n",
    "def save_topics(src: Path, dst: Path, topics: list) -> None:\n",
    "    \"\"\"Remove topic from rosbag2.\n",
    "\n",
    "    Args:\n",
    "        src: Source path.\n",
    "        dst: Destination path.\n",
    "        topic: list of topics to save\n",
    "    \"\"\"\n",
    "    \n",
    "    with Reader(src) as reader, Writer(dst) as writer:\n",
    "        conn_map = {}\n",
    "        for conn in reader.connections:\n",
    "            if conn.topic in topics:\n",
    "                ext = cast(ConnectionExtRosbag2, conn.ext)\n",
    "                conn_map[conn.id] = writer.add_connection(\n",
    "                    conn.topic,\n",
    "                    conn.msgtype,\n",
    "                    serialization_format = ext.serialization_format,\n",
    "                    offered_qos_profiles = ext.offered_qos_profiles,\n",
    "                )\n",
    "            else: \n",
    "                continue\n",
    "\n",
    "        rconns = [reader.connections[x-1] for x in conn_map]\n",
    "        for conn, timestamp, data in reader.messages(connections=rconns):\n",
    "            writer.write(conn_map[conn.id], timestamp, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['/velodyne_points']\n",
    "# Change the directories to your data directories\n",
    "save_topics('/home/r/records', '/home/r/records/bag',topics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the map from the LOAM results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DATATYPES = {}\n",
    "_DATATYPES[PointField.INT8]    = ('b', 1)\n",
    "_DATATYPES[PointField.UINT8]   = ('B', 1)\n",
    "_DATATYPES[PointField.INT16]   = ('h', 2)\n",
    "_DATATYPES[PointField.UINT16]  = ('H', 2)\n",
    "_DATATYPES[PointField.INT32]   = ('i', 4)\n",
    "_DATATYPES[PointField.UINT32]  = ('I', 4)\n",
    "_DATATYPES[PointField.FLOAT32] = ('f', 4)\n",
    "_DATATYPES[PointField.FLOAT64] = ('d', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_points(cloud, field_names=None, skip_nans=False, uvs=[]):\n",
    "\n",
    "    fmt = _get_struct_fmt(cloud.is_bigendian, cloud.fields, field_names)\n",
    "    width, height, point_step, row_step, data, isnan = cloud.width, cloud.height, cloud.point_step, cloud.row_step, cloud.data, math.isnan\n",
    "    unpack_from = struct.Struct(fmt).unpack_from\n",
    "\n",
    "    if skip_nans:\n",
    "        if uvs:\n",
    "            for u, v in uvs:\n",
    "                p = unpack_from(data, (row_step * v) + (point_step * u))\n",
    "                has_nan = False\n",
    "                for pv in p:\n",
    "                    if isnan(pv):\n",
    "                        has_nan = True\n",
    "                        break\n",
    "                if not has_nan:\n",
    "                    yield p\n",
    "        else:\n",
    "            for v in range(height):\n",
    "                offset = row_step * v\n",
    "                for u in range(width):\n",
    "                    p = unpack_from(data, offset)[:3]\n",
    "                    has_nan = False\n",
    "                    for pv in p:\n",
    "                        if isnan(pv):\n",
    "                            has_nan = True\n",
    "                            break\n",
    "                    if not has_nan:\n",
    "                        yield p\n",
    "                    offset += point_step\n",
    "    else:\n",
    "        if uvs:\n",
    "            for u, v in uvs:\n",
    "                yield unpack_from(data, (row_step * v) + (point_step * u))\n",
    "        else:\n",
    "            for v in range(height):\n",
    "                offset = row_step * v\n",
    "                for u in range(width):\n",
    "                    yield unpack_from(data, offset)[:3]\n",
    "                    offset += point_step\n",
    "\n",
    "def _get_struct_fmt(is_bigendian, fields, field_names=None):\n",
    "    fmt = '>' if is_bigendian else '<'\n",
    "\n",
    "    offset = 0\n",
    "    for field in (f for f in sorted(fields, key=lambda f: f.offset) if field_names is None or f.name in field_names):\n",
    "        if offset < field.offset:\n",
    "            fmt += 'x' * (field.offset - offset)\n",
    "            offset = field.offset\n",
    "        if field.datatype not in _DATATYPES:\n",
    "            print('Skipping unknown PointField datatype [%d]' % field.datatype, file=sys.stderr)\n",
    "        else:\n",
    "            datatype_fmt, datatype_length = _DATATYPES[field.datatype]\n",
    "            fmt    += field.count * datatype_fmt\n",
    "            offset += field.count * datatype_length\n",
    "\n",
    "    return fmt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Play the rosbag and extract the last point cloud in the topic ```/laser_cloud_map```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aft_mapped_to_init nav_msgs/msg/Odometry\n",
      "/velodyne_cloud_registered sensor_msgs/msg/PointCloud2\n",
      "/laser_cloud_map sensor_msgs/msg/PointCloud2\n"
     ]
    }
   ],
   "source": [
    "scan = o3d.geometry.PointCloud()\n",
    "# Change the path here to you data path\n",
    "with AnyReader([Path('/home/r/Desktop/map/bag.bag')]) as reader:\n",
    "    # topic and msgtype information is available on .connections list\n",
    "    for connection in reader.connections:\n",
    "        print(connection.topic, connection.msgtype)\n",
    "    for connection, timestamp, rawdata in reader.messages():\n",
    "        if connection.topic == '/laser_cloud_map':\n",
    "            msg = reader.deserialize(rawdata, connection.msgtype)\n",
    "            points_as_array = np.array(list(read_points(msg, skip_nans=True)))\n",
    "            scan.points = o3d.utility.Vector3dVector(points_as_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualiz the Map and save it as .pcd file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.io.write_point_cloud(\"map.pcd\", scan)\n",
    "o3d.visualization.draw_geometries([scan])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aruco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "815f23c7e134538287fa75783806fca39f21276c52058111af811b0613b54573"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
